{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da88a427-bcf3-4a4e-8990-4223071e0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")  # access to local modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b459819-7788-4836-8f7f-df95c12de7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 07:41:59.681609: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.train import (\n",
    "    BytesList,\n",
    "    FloatList,\n",
    "    Int64List,\n",
    "    Feature,\n",
    "    Features,\n",
    "    Example\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d9cbdc-fdee-43b8-b307-34586ebc71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLDemo import DataPulling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c520b32-35d4-4d97-89dc-47cea04ae39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUSING_DIRECTORY = \".tmp/housing\"\n",
    "N_READERS: int = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41aab9f2-c3ac-4fe0-b5a7-981124375233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 07:42:01.948906: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:920] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 07:42:03.817791: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:920] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 07:42:03.817837: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:920] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 07:42:03.817847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2397] Ignoring visible gpu device (device: 0, name: AMD Radeon Graphics, pci bus id: 0000:65:00.0) with AMDGPU version : gfx1103. The supported AMDGPU versions are gfx900, gfx906, gfx908, gfx90a, gfx940, gfx941, gfx942, gfx1030, gfx1100, gfx1101, gfx1102, gfx1200, gfx1201.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(10)\n",
    "dataset: tf.data.Dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b988a6-483d-4e3a-8870-acff64562f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 07:42:03.840271: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7d8ef3-821c-4ac5-9d31-3264a31570a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=4>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=7>}\n",
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=5>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=8>}\n",
      "{'a': (<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=6>), 'b': <tf.Tensor: shape=(), dtype=int32, numpy=9>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 07:42:03.852094: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "x_nested = {\"a\": ([1, 2, 3], [4, 5, 6]), \"b\": [7, 8, 9]}\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x_nested)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fffe654-0b44-42e4-a9cc-9c8716a27e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b446cb8b-7b6b-4653-bf36-023634988a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 07:42:03.878057: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "dataset = dataset.repeat(3).batch(7, drop_remainder=True)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55bfd8be-bbdb-4077-8af2-69f26a22be4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "dataset = dataset = dataset.repeat(3).batch(7).map(lambda x: x * 2)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb898b06-a9ae-4bbf-967d-f8cc311ba2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "dataset = dataset.repeat(3).batch(7).map(lambda x: x * 2, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.filter(lambda x: tf.reduce_sum(x) > 50)  # do only one lambda per line!\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df0495d6-1108-47da-a02e-d6bca163eea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 4 2 3 5 0 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([9 8 2 0 3 1 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 7 9 6 7 8], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(2)\n",
    "dataset = dataset.shuffle(buffer_size=4, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59f06ff2-27b0-490c-8380-0294b3dcd3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = DataPulling.to_randomized_files(DataPulling.open_tgz(DataPulling.HOUSING)[0][1], HOUSING_DIRECTORY, number_of_files=50)\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee56adb-e7f6-45c8-93e1-eba8a584c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = filepath_dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1), cycle_length=N_READERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f75f009e-2f80-45ef-a0d3-c6d4fc611ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'3298,-118.15,33.91,35.0,1590.0,350.0,1299.0,335.0,4.0313,163200.0,<1H OCEAN', shape=(), dtype=string)\n",
      "tf.Tensor(b'4916,-119.69,36.81,13.0,1524.0,366.0,994.0,370.0,2.5446,93800.0,INLAND', shape=(), dtype=string)\n",
      "tf.Tensor(b'3386,-119.19,35.41,12.0,2835.0,471.0,1399.0,413.0,4.4125,149000.0,INLAND', shape=(), dtype=string)\n",
      "tf.Tensor(b'15543,-118.33,34.02,46.0,2223.0,361.0,968.0,373.0,4.26,182600.0,<1H OCEAN', shape=(), dtype=string)\n",
      "tf.Tensor(b'10746,-117.06,32.56,17.0,2803.0,683.0,2768.0,676.0,1.7958,140400.0,NEAR OCEAN', shape=(), dtype=string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 07:42:04.087311: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.take(5):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13a29a7a-97df-4a05-85ff-622970841714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_line(line, n_inputs=8):\n",
    "    defs = [tf.constant([], dtype=tf.float32)] + [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    return tf.stack(fields[1:-2]), tf.stack(fields[-2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "856795b5-a592-45dc-9352-005e35b0dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(line):\n",
    "    x, y = parse_csv_line(line)\n",
    "    # todo normalization\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "860df874-d4fa-4315-84b1-5262fc8940aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, n_readers=5, nread_threads=None, n_parse_threads=5, shuffle_buffer_size=10000, seed=42, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths, seed=seed)\n",
    "    dataset = dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1), cycle_length=n_readers, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size, seed=seed)\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83e120d2-ae2f-48bb-bea3-a2fc72b59422",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = csv_reader_dataset(train_filepaths[:30])\n",
    "valid_set = csv_reader_dataset(train_filepaths[30:40])\n",
    "test_set = csv_reader_dataset(train_filepaths[40:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccbe24f1-0620-4004-951e-8dc1a1259120",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\".tmp/my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first line\")\n",
    "    f.write(b\"This is the second line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35157449-8704-467d-8a6f-96febada2dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first line', shape=(), dtype=string)\n",
      "b'This is the first line'\n",
      "This is the first line\n",
      "tf.Tensor(b'This is the second line', shape=(), dtype=string)\n",
      "b'This is the second line'\n",
      "This is the second line\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset([\".tmp/my_data.tfrecord\"])\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "    print(item.numpy())\n",
    "    print(item.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ffc463c-481c-4f6a-b508-97a1b86e0d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\".tmp/my__compressed_data.tfrecord\", options) as f:\n",
    "    f.write(b\"This is a compressed line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ac46ac0-4a68-48a0-9ebb-799303de4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is a compressed line', shape=(), dtype=string)\n",
      "b'This is a compressed line'\n",
      "This is a compressed line\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset([\".tmp/my__compressed_data.tfrecord\"], compression_type=\"GZIP\")\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "    print(item.numpy())\n",
    "    print(item.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21d1994a-69ee-47f4-9ab7-5a70a5c21703",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_example = Example(\n",
    "    features=Features(\n",
    "        feature = {\n",
    "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
    "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", b\"c@d.com\"]))\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4b8b2e3-8d42-437f-b44b-9aa41e94d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\".tmp/my_contacts.tfrecord\") as f:\n",
    "    for _ in range(5):\n",
    "        f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebe84851-9da5-4245-ab35-83658539e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"emails\": tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "\n",
    "def parse(serialized_examples):\n",
    "    # return tf.io.parse_single_example(serialized_examples, feature_description)\n",
    "    return tf.io.parse_example(serialized_examples, feature_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1cdd360-8b69-4103-bdcb-7d5b8fa30b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}\n",
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}\n",
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}\n",
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}\n",
      "{'emails': SparseTensor(indices=tf.Tensor(\n",
      "[[0]\n",
      " [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)), 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>, 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset([\".tmp/my_contacts.tfrecord\"]).map(parse)\n",
    "for parsed_example in dataset:\n",
    "    print(parsed_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7d933-adec-4c82-8fc0-fa8bba611cd6",
   "metadata": {},
   "source": [
    "# Normalization Layers in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a77d3ab-b1a4-4e93-973b-12fa42a00d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d260d2c6-0c62-4f2f-a5e7-9df69b34a659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 4.5333 - val_loss: 2.2754\n",
      "Epoch 2/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 0.8457 - val_loss: 0.6168\n",
      "Epoch 3/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.6299 - val_loss: 0.8097\n",
      "Epoch 4/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.5914 - val_loss: 0.9616\n",
      "Epoch 5/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 0.5951 - val_loss: 0.6150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c0a1c1f11c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# including in the model with training\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "model = tf.keras.models.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=2e-3))\n",
    "norm_layer.adapt(X_train)  # this calculates the mean and standard deviation of X_train\n",
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0115fdd-88ec-4711-b7f3-0f241828ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - loss: 3.8299 - val_loss: 1.3675\n",
      "Epoch 2/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 0.8667 - val_loss: 0.6552\n",
      "Epoch 3/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 0.6846 - val_loss: 1.4635\n",
      "Epoch 4/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 0.6466 - val_loss: 0.6793\n",
      "Epoch 5/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - loss: 0.6458 - val_loss: 0.9527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c0a1c068b00>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not in training phase for speedup\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "norm_layer.adapt(X_train)\n",
    "X_train_scaled = norm_layer(X_train)\n",
    "X_valid_scaled = norm_layer(X_valid)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.SGD(learning_rate=2e-3))\n",
    "model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4db32f3-ccdc-47b2-b5ac-a3b48bf0d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUUUUUSIOOOOON!\n",
    "final_model = tf.keras.Sequential([norm_layer, model])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae67d0b-2748-40ea-bc2e-ffe81311471d",
   "metadata": {},
   "source": [
    "## Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e98786aa-4e55-4aff-ae23-f423d5127adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.constant([[10.], [93.], [57.], [18.], [37.], [5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca22d903-2d45-487d-a81c-be58102fc04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 1), dtype=int64, numpy=\n",
       "array([[0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretize_layer = tf.keras.layers.Discretization(bin_boundaries=[18., 50.])\n",
    "age_categories = discretize_layer(age)\n",
    "age_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e19932f-2090-415a-9082-1984a15d7395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 1), dtype=int64, numpy=\n",
       "array([[1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretize_layer = tf.keras.layers.Discretization(num_bins=3)\n",
    "discretize_layer.adapt(age)\n",
    "age_categories = discretize_layer(age)\n",
    "age_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30fbba2e-e205-443f-a8c9-21458c07f631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoder\n",
    "onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3)\n",
    "onehot_layer(age_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e9256f9-6887-452a-9dce-f2dd791b9a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_age_categories = np.array([[1, 0], [2, 2], [2, 0]])\n",
    "onehot_layer(two_age_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "208966f3-6a7c-4619-86d7-c7667ce883cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 6), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_layer = tf.keras.layers.CategoryEncoding(num_tokens=3 + 3)\n",
    "onehot_layer(two_age_categories + [0, 3])  # shift by three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cde7e211-f7a2-4cf0-8038-33378dd226e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\n",
       "array([[1],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0]])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = [\"Auckland\", \"Paris\", \"Paris\", \"San Francisco\"]\n",
    "str_lookup_layer = tf.keras.layers.StringLookup()\n",
    "str_lookup_layer.adapt(cities)\n",
    "str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Auckland\"], [\"Montreal\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7be81594-d13d-4449-94fb-eb02e044e6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=int64, numpy=\n",
       "array([[0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0]])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_lookup_layer = tf.keras.layers.StringLookup(output_mode=\"one_hot\")\n",
    "str_lookup_layer.adapt(cities)\n",
    "str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Auckland\"], [\"Montreal\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bef8eda-75c4-4515-8996-ea17b176a8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       "array([[5],\n",
       "       [7],\n",
       "       [4],\n",
       "       [3],\n",
       "       [4]])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_lookup_layer = tf.keras.layers.StringLookup(num_oov_indices=5)  # oov = out of vocabulary\n",
    "str_lookup_layer.adapt(cities)\n",
    "str_lookup_layer([[\"Paris\"], [\"Auckland\"], [\"Foo\"], [\"Bar\"], [\"Baz\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0982327b-f37d-44c4-9950-a7ae392f4b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=int64, numpy=\n",
       "array([[0],\n",
       "       [1],\n",
       "       [9],\n",
       "       [1]])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashing_layer = tf.keras.layers.Hashing(num_bins=10)  # do not use if possible since this can still create collisions\n",
    "hashing_layer([[\"Paris\"], [\"Tokyo\"], [\"Auckland\"], [\"Montreal\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c5f244a-e091-4095-91c6-9ea69664da22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[-0.04668725,  0.04036435],\n",
       "       [ 0.0357411 , -0.02600536],\n",
       "       [-0.04668725,  0.04036435]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=5, output_dim=2)\n",
    "embedding_layer(np.array([2, 4, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0841d6ce-a306-49b5-b09b-1a6db88fab26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 0.04587116, -0.02930641],\n",
       "       [ 0.03589033, -0.04210738],\n",
       "       [ 0.04587116, -0.02930641]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string embedding\n",
    "tf.random.set_seed(42)\n",
    "ocean_prox = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
    "str_lookup_layer = tf.keras.layers.StringLookup()\n",
    "str_lookup_layer.adapt(ocean_prox)\n",
    "lookup_and_embed = tf.keras.models.Sequential([str_lookup_layer, tf.keras.layers.Embedding(input_dim=str_lookup_layer.vocabulary_size(), output_dim=2)])\n",
    "lookup_and_embed(np.array([\"<1H OCEAN\", \"ISLAND\", \"<1H OCEAN\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d795eee-96e5-4b86-8696-a1a232ad1d3d",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ac08faf-588f-4d6a-a3e1-0398ec1ec856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=int64, numpy=\n",
       "array([[2, 1, 0, 0],\n",
       "       [6, 2, 1, 2]])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = [\"To be\", \"!(to be)\", \"That's the question\", \"be, be, be.\"]\n",
    "text_vec_layer = tf.keras.layers.TextVectorization()\n",
    "text_vec_layer.adapt(train_data)\n",
    "text_vec_layer([\"Be good!\", \"Question: be or be?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11173aa6-752c-43c3-8093-aa6c00bb72e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
       "array([[0.96725637, 0.6931472 , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.96725637, 1.3862944 , 0.        , 0.        , 0.        ,\n",
       "        1.0986123 ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(output_mode=\"tf_idf\")  # term-frequency x inverse-document-frequency\n",
    "text_vec_layer.adapt(train_data)\n",
    "text_vec_layer([\"Be good!\", \"Question: be or be?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd63173-c9ed-4dd9-a02a-55b138ff9196",
   "metadata": {},
   "source": [
    "## TensorFlow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3eb8ce0-930d-436b-b23b-9a5fbdda579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  geht gerade nicht... import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fbccb8-342e-45c1-a496-53f8e1f2fb48",
   "metadata": {},
   "source": [
    "## Image Preprocessing Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22f0dd33-31be-47b5-ab9c-737a0f8a98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_images\n",
    "\n",
    "images = load_sample_images()[\"images\"]\n",
    "crop_image_layer = tf.keras.layers.CenterCrop(height=100, width=100)\n",
    "cropped_images = crop_image_layer(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf91ec-b91f-4bdf-9006-01546d944e0a",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07f32be7-db11-4095-91ac-52dc649979b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8b1b465-2907-4dd8-8779-4ada4cd5cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in mnist_train.shuffle(10000, seed=42).batch(32).prefetch(1):\n",
    "    images = batch[\"image\"]\n",
    "    labels = batch[\"label\"]\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "797bf1e3-c959-4ada-8ae8-05e676efb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = mnist_train.shuffle(buffer_size=10000, seed=42).batch(32)\n",
    "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "mnist_train = mnist_train.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e36e70-f88c-42bd-a25f-2aab4ba12e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
